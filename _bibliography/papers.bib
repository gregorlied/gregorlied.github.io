---
---

@article{DiTMC2025,
  abbr={NeurIPS},
  title={Sampling 3D Molecular Conformers with Diffusion Transformers},
  author={Frank*, J Thorben and Ripken*, Winfried and Lied*, Gregor and MÃ¼ller, Klaus-Robert and Unke, Oliver T and Chmiela, Stefan},
  abstract={Diffusion Transformers (DiTs) have demonstrated strong performance in generative modeling, particularly in image synthesis, making them a compelling choice for molecular conformer generation. However, applying DiTs to molecules introduces novel challenges, such as integrating discrete molecular graph information with continuous 3D geometry, handling Euclidean symmetries, and designing conditioning mechanisms that generalize across molecules of varying sizes and structures. We propose DiTMC, a framework that adapts DiTs to address these challenges through a modular architecture that separates the processing of 3D coordinates from conditioning on atomic connectivity. To this end, we introduce two complementary graph-based conditioning strategies that integrate seamlessly with the DiT architecture. These are combined with different attention mechanisms, including both standard non-equivariant and SO(3)-equivariant formulations, enabling flexible control over the trade-off between between accuracy and computational efficiency. Experiments on standard conformer generation benchmarks (GEOM-QM9, -DRUGS, -XL) demonstrate that DiTMC achieves state-of-the-art precision and physical validity. Our results highlight how architectural choices and symmetry priors affect sample quality and efficiency, suggesting promising directions for large-scale generative modeling of molecular structures. Code is available at https://github.com/ML4MolSim/dit_mc.},
  journal={In Advances in Neural Information Processing Systems},
  year={2025},
  arxiv={2506.15378},
  code={https://github.com/ML4MolSim/dit_mc},
  openreview={tmbx9zGVWb},
  preview={ditmc.gif},
  selected={true},
}
